### 정형, 반정형, 비정형 데이터의 이해
01. 정형 데이터(Structured data)
: 의미를 파악하기 쉽고, 규칙적인 데이터 / 정형화된 스키마 구조, DBMS에 내용이 저장될 수 있는 구조
(Gender라는 컬럼 - male, female)

02. 비정형 데이터(Unstructured data)
: 정해진 규칙이 없어서 값의 의미를 파악하기 어려운 데이터 / 수집 데이터 각각이 데이터 객체로 구분, 고정 필드 및 메타데이터가 정의되지 않음
(텍스트, 음성 ,영상 등)
3V : Velocity(속도), Volume(양), Variety(다양) => 비정형 데이터는 Variety에 속한다.

03. 반정형 데이터(Semi-structured data)
: 데이터 내부의 데이터 구조에 대한 메타 정보가 포함된 구조
(HTML, XML같은 포맷)


### 데이터 전처리
01. 평활화 : 데이터로부터 잡음을 제거하기 위해 데이터 추세에 벗어나는 값들을 변환하는 기법
02. 집계 : 다양한 차원의 방법으로 데이터를 요약하는 기법
03. 정규화 : 데이터를 정해진 구간 내에 들도록 하는 기법
04. 일반화 : 특정 구간에 분포하는 값으로 스케일을 변화시키는 기법


### 척도(Scale)의 종류
01. 명목 척도 : 단순히 집단의 분류를 목적으로 사용된 척도
02. 서열 척도 : 측정 대상 사이의 대소 관계를 나타내기 위한 척도
03. 구간척도(등간 척도) : 서열과 의미 있는 차이를 가지는 척도
04: 비율척도 : 구간척도의 성질을 가지며 척도 간의 비율(Ratio)도 의미가 있는 척도


### R의 데이터 유형 이해 
01. 벡터 
- R에서 데이터를 저장하는 기본적인 단위로 동일한 데이터 타입의 여러 값을 저장하는 객체
- 1차원 배열 형태로 특정 항목의 요소를 사용하려면 벡터명[색인] 를 사용한다.
- 각 벡터의 요소에 names()함수를 사용해서 이름을 지정할 수 있다.
02. matrix
- 2차원 데이터 구조를 나타내는 자료형
- 행(row)과 열(column)로 구성되며, 모든 원소는 동일한 데이 터 타입을 가진다.
03. list : 
- 여러가지 데이터 유형을 포함할 수 있는 유연한 자료구조
- 서로 다른 데이터 타입의 원소들을 하나의 객체로 그룹화 하여 저장하는데 사용된다.
04. data.frame 
- 테이블 형태의 데이터 구조를 나타내는 자로형
- 서로 다른 데이터 타입의 열(column)로 구성된 데이터를 저장하며, 각 열은 동일한 길이를 가져야 한다.


### 시각화 그래프 종류 
관찰점들을 표시하는 시각화 방법? => 스캐터(Scatter) 차트
연속형 자료에 대한 도수분포표를 시각화한 그래프? => 히스토그램
범주별 빈도를 요약해서 나타낸 시각화한 그래프? => 막대(bar)그래프


### R 언어의 특성 
- 데이터 조작, 계산 및 시각화를 지원하는 데이터 분석 환경 제공
- 벨 연구소에서 만들어진 통계 분석 언어인 S에 근간을 두고있다.
- GPL(General Public License)로 배포되는 오픈소스 소프트웨어
- Cross-platform 지원
- Interpreter Language
- 통계, 기계, 학습, 금융, 생물정보학, 그래픽스에 이르는 다양한 12,000개 이상의 통계 분석 관련 패키지
- 데이터 구조 연산을 수행할 수 있다.
- 파이썬에 비해서 강력한 점은 시각화


## 회귀분석의 다양한 유형
### 01. 선형 회귀(Linear Regression) 모델의 이해
- 머신러닝의 가장 큰 목적은 실제 데이터를 바탕으로 모델을 생성해서 만약 다른 값을 넣었을 때 발생할 아웃풋을 예측하는 데 있다.
- 가장 직관적이고 간단한 모델은 선(line)이다. 데이터를 가장 잘 설명하는 선을 찾는 분석 방법을 선형 회귀(Linear Regression)분석이라 한다. (최적적합선)
(키값 기반으로 몸무게 예측, 공부한 시간 기반으로 점수 예측, 기값 기반으로 발사이즈 예측 등)
- 직선 그래프를 그리는 1차 함수로 표현 y = mx + b
- 선형 회구는 데이터를 가장 잘 설명하는 기울기 m, 절편 b를 찾는 것
- 일반 선형 회귀, 릿지(Ridge), 

### 02. 로지스틱 회귀(Logistic Regression)
-  0 또는 1, 참 또는 거짓, 흑 또는 백, 스팸 또는 스팸 아닌 것 등의 두 가지 값 중 하나만 취할 수 있는 경우 로지스틱 회귀를 사용하여 데이터를 분석할 수 있다.

### 03. 리지(Ridge Regression)
- 리지 회귀는 정규화 또는 규제화(regularization) 기법으로 알려져 있으며 모델의 복잡성을 줄이는 데 사용된다. 또한 ‘리지 회귀 페널티’로 알려진 약간의 편향, 즉 바이어스(bias)를 사용하여 모델이 과대적합(overfitting)에 덜 취약하게 만든다.

### 04. 다항 회귀(Polynomial regression)
- 다항 회귀는 선형 모델을 사용하여 비선형 데이터 집합을 모델링한다.
- 다항 회귀는 독립 변수가 여러 개인 선형 회귀를 뜻하는 다중 선형 회귀와 비슷한 방식으로 작동하지만, 비선형 곡선을 사용한다.


### 부트 스트래핑을 사용한 앙상블 학습 알고리즘 => 배깅(Bagging)
- 앙상블 학습의 유형 : 보팅(Voting), 배깅(Bagging), 부스팅(Boosting), 스태킹(Stacking)
01. 보팅(Voting) : 여러 종류의 알고리즘을 사용한 각각의 결과에 대해 투표를 통해 최종 결과를 예측하는 방식
02. 배깅(Bagging) : 
- 개별 분류기가 부트 스트래핑 방식으로 샘플링된 데이터 세트에 대해서 학습을 통해 개별적인 예측을 수행한 결과를 보팅을 통해서 최종 예측 결과를 선정하는 방식
- 같은 알고리즘에 대해 데이터 샘플을 다르게 두고 학습을 수행해 보팅을 수행하는 방식
03. 부스팅(Boosting) : 여러 개의 알고리즘이 순차적으로 학습을 하되, 앞에 학습한 알고리즘 예측이 틀린 데이터에 대해 올바르게 예측할 수 있도록, 그 다음번 알고리즘에 가중치를 부여하여 학습과 예측을 진행하는 방식
04. 스태킹(Stacking) : 여러 가지 다른 모델의 예측 결과값을 다시 학습 데이터로 만들어 다른 모델(메타 모델)로 재 학습시켜 결과를 예측하는 방법


### 은닉층(Hidden Layer)에서 가중치 조정이 이루어지지 않아 신경망의 학습이 제대로 이루어지지 않는 현상은? => 그래디언트 소실(vanishing gradient)
- 그래디언트 소실은 역전파 알고리즘으로 심층 신경망을 학습시키는 과정에서, 출력층에서 멀어질수록 신경망의 출력 오차가 반영되지 않는 현상을 말한다.
- 오차가 앞쪽의 레이어까지 전달이 안돼 가중치가 변화가 되지 않는다. 즉 학습되지 않는 현상. 


### 딥러닝 신경망 모델의 특징 이해
01. CNN(Convolutional Neural Networks) ConvNet
- 입력 데이터에 대해 2D 컨벌루션 레이어를 사용으로써 특징을 추출, 이미지와 같은 2차원 데이터 처리에 적합한 아키텍처
02. 순환신경망(RNN. Recurrent Neural Network) 
- 순차적 정보가 담긴 데이터에서 규칙적인 패턴을 인식하고, 추상화 된 정보를 추출
- 텍스트, 음성, 음악, 영상 등 순차적 데이터를 다루는 데 적합
03. GAN(Generative Adversarial Network. 생성 대립 신경망)
- 비지도 학습 방법, 훈련으로 학습된 패턴을 이용해 이미지나 음성을 생성할 수 있다.
- GAN은 이미지 및 음성 복원 등에 적용된다.


### 퍼셉트론(Perceptron) 
- 다수의 입력으로부터 하나의 결과를 내보내는 알고리즘 각각의 입력값에 가중치 곱의 힘을 신경망에 보내고 활성화함수(임계치)를 사용하여 임계치를 넘으면 출력 신호로 1을 출력하고. 임계치를 넘지 못하면 0을 출력한다. 

### 다층 퍼셉트론(MLP)에서 기울기 소실의 원인?
- 은닉층을 많이 거칠수록 전달되는 오차가 크게 줄어들어 학습이 되지 않는 현상이 발생하는데, 이를 기울기 소멸 문제라고 한다.
- 기울기 소실 문제 해결을 위한 활성화 함수 : relu, thnh, leekyrelu, sigmoid


### 출력층에서 사용하는 활성화 함수 종류와 특성 이해
#### 활성화 함수(Activation function)란?
- 출력값을 활성화를 일으키게 할 것인가를 정하고 그 값을 부여하는 함수
- 활서오하 함수를 사용하면 입력값에 대한 출력값이 linear하게 나오지 않으므로 linear system을 non-linear한 systemd으로 바꿀 수 있다.

#### 활성화 함수 종류
01. sigmoid
- 입력값 x 값이 작아질수록 0에 수렴하고, 커질수록 1에 수렴한다. (Logistic 함수, S자형 함수 )
02. softmax
- 출력층에서 주로 사용한다.
- 세 가지 이상의(상호 배타적인) 선택지 중 하나를 고르는 다중 클래스 분류 문제에 주로 사용한다.
03. Stop Function
- 출력값이 0이 될지, 1이 될지를 결정
- 계단 모양 함수로, 특정값 이하는 0, 특정값 이상은 1로 출력하도록 만들어진 함수
04. ReLU
- 음수를 입력하면 0을 출력하고, 양수를 입력하면 입력값을 그대로 반환한다.
- x가 0보다 크면 기울기가 1인 직선, 0보다 작으면 함수 값이 0이 된다.
05. Leaky ReLU
06.Hyperbolic tangent function


# 서포트 벡터 머신 분류 모델 특성 이해
### 군집 분석의 특성 이해
- 비슷한 유형의 데이터 그룹을 찾는다.(데이터 경향성을 파악하는 비지도 학습)

# 이미지 분류 분석에서 신경망을 이용한 이미지의 특성 추출하는 단계?


### 하이퍼파라미터란?
- 최적의 훈련 모델을 구현하기 위해 모델에서 설정하는 변수로 학습률(Learning & Late), 에포크 수(훈련 반복 횟수), 가중치 초기화 등을 결정 할 수 있다.
- 하이퍼파라미터 튜닝 기법으로 훈련 모델의 최적값을 찾을 수 있다.

#### 하이퍼파라미터 특징
- 모델의 매개 변수를 추징하는 데 도움이 되는 프로세스에 사용된다.
- 개발자에 의해 수동으로 설정할 수 있다. (임의 조정 가능)
- 학습 알고리즘의 샘플에 대한 일반화를 위해 조절된다.

#### 하이퍼파라미터 튜닝기법
- 그리드 탐색
- 랜덤 탐색
- 베이지안 최적화
- 휴리스틱 탐색

#### [정리]
- 모델 파라미터는 새로운 샘플이 주어지면 무엇을 예측할지 결정하기 위해 사용하는 것이며, 학습 모델에 의해 결정된다.
- 하이퍼파라미터는 학습 알고리즘 자체의 파라미터로 모델이 새로운 샘플에 잘 일반화 되도록 최적값을 찾으나, 데이터 분석 결과로 얻어지는 값이 아니므로 절대적인 최적값은 존재하지 않고, 사용자가 직접 설정해애 한다.


# 최적화 알고리즘 함수별 특성 이해


### RNN 신경망 이해와 특징?
- 순차적인 데이터
- 시계열 데이터 분석에 사용되는 신경망 모델
- 은닉층의 출력을 다음 은닉층의 입력으로 보내고, 출력층으로 보낸다. (누적)
- 은닉층의 노드를 'cell'이라고 하며, 기억 기능을 가진다.


# 혼동 행렬(Confusion Matrix)을 통한 모형의 평가지표에서 계산할 수 있는 정확률, 재현율, 정밀도 공식

### 모델 학습시에 과적합 방지를 위해 적용할 수 있는 방법들?
- 데이터 셋 증가, 모델 복잡도 감소
- 가중치 
- Dropout() : 과적합 줄이기 위해 optional
